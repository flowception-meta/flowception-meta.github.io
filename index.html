<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Flowception: Temporally Expansive Flow Matching for Video Generation - Berrada Ifriqi et al.">
  <meta name="description" content="A novel non-autoregressive and variable-length video generation framework that interleaves discrete frame insertions with continuous frame denoising.">
  <meta name="keywords" content="video generation, flow matching, non-autoregressive, frame insertion, video synthesis, generative models, machine learning, computer vision, AI">
  <meta name="author" content="Tariq Berrada Ifriqi, John Nguyen, Karteek Alahari, Jakob Verbeek, Ricky Chen">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="FAIR at Meta & Inria">
  <meta property="og:title" content="Flowception: Temporally Expansive Flow Matching for Video Generation">
  <meta property="og:description" content="A novel non-autoregressive and variable-length video generation framework that interleaves discrete frame insertions with continuous frame denoising.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Flowception: Temporally Expansive Flow Matching for Video Generation - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Tariq Berrada Ifriqi">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="video generation">
  <meta property="article:tag" content="flow matching">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@MetaAI">
  <meta name="twitter:creator" content="@MetaAI">
  <meta name="twitter:title" content="Flowception: Temporally Expansive Flow Matching for Video Generation">
  <meta name="twitter:description" content="A novel non-autoregressive and variable-length video generation framework that interleaves discrete frame insertions with continuous frame denoising.">
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="Flowception: Temporally Expansive Flow Matching for Video Generation - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Flowception: Temporally Expansive Flow Matching for Video Generation">
  <meta name="citation_author" content="Berrada Ifriqi, Tariq">
  <meta name="citation_author" content="Nguyen, John">
  <meta name="citation_author" content="Alahari, Karteek">
  <meta name="citation_author" content="Verbeek, Jakob">
  <meta name="citation_author" content="Chen, Ricky">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>Flowception: Temporally Expansive Flow Matching for Video Generation - Berrada Ifriqi et al. | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Flowception: Temporally Expansive Flow Matching for Video Generation",
    "description": "A novel non-autoregressive and variable-length video generation framework that interleaves discrete frame insertions with continuous frame denoising.",
    "author": [
      {
        "@type": "Person",
        "name": "Tariq Berrada Ifriqi",
        "affiliation": [
          {
            "@type": "Organization",
            "name": "FAIR at Meta"
          },
          {
            "@type": "Organization",
            "name": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK"
          }
        ]
      },
      {
        "@type": "Person",
        "name": "John Nguyen",
        "affiliation": {
          "@type": "Organization",
          "name": "FAIR at Meta"
        }
      },
      {
        "@type": "Person",
        "name": "Karteek Alahari",
        "affiliation": {
          "@type": "Organization",
          "name": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK"
        }
      },
      {
        "@type": "Person",
        "name": "Jakob Verbeek",
        "affiliation": {
          "@type": "Organization",
          "name": "FAIR at Meta"
        }
      },
      {
        "@type": "Person",
        "name": "Ricky Chen",
        "affiliation": {
          "@type": "Organization",
          "name": "FAIR at Meta"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["video generation", "flow matching", "non-autoregressive", "frame insertion", "video synthesis", "generative models", "machine learning", "computer vision"],
    "abstract": "We present Flowception, a novel non-autoregressive and variable-length video generation framework. Flowception learns a probability path that interleaves discrete frame insertions with continuous frame denoising. Compared to autoregressive methods, Flowception alleviates error accumulation/drift as the frame insertion mechanism during sampling serves as an efficient compression mechanism to handle long-term context. Compared to full-sequence flows, our method reduces FLOPs for training three-fold, while also being more amenable to local attention variants, and allowing to learn the length of videos jointly with their content. Quantitative experimental results show improved FVD and VBench metrics over autoregressive and full-sequence baselines, which is further validated with qualitative results. Finally, by learning to insert and denoise frames in a sequence, Flowception seamlessly integrates different tasks such as image-to-video generation and video interpolation.",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Video Generation"
      },
      {
        "@type": "Thing",
        "name": "Flow Matching"
      }
    ]
  }
  </script>

  <!-- MathJax config + loader -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Flowception: Temporally Expansive Flow Matching for Video Generation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Tariq Berrada Ifriqi</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">John Nguyen</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Karteek Alahari</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Jakob Verbeek</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Ricky Chen</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>FAIR at Meta, <sup>2</sup>Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, France</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
<!--                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
-->
		    
                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/main_fig2.jpg" alt="Flowception method overview" loading="eager"/>
      <h2 class="subtitle has-text-centered">
        Flowception seamlessly integrates frame insertion and denoising for efficient, high-quality video generation with reduced error accumulation compared to autoregressive methods.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present Flowception, a novel non-autoregressive and variable-length video generation framework. Flowception learns a probability path that interleaves discrete frame insertions with continuous frame denoising. Compared to autoregressive methods, Flowception alleviates error accumulation/drift as the frame insertion mechanism during sampling serves as an efficient compression mechanism to handle long-term context. Compared to full-sequence flows, our method reduces FLOPs for training three-fold, while also being more amenable to local attention variants, and allowing to learn the length of videos jointly with their content. Quantitative experimental results show improved FVD and VBench metrics over autoregressive and full-sequence baselines, which is further validated with qualitative results. Finally, by learning to insert and denoise frames in a sequence, Flowception seamlessly integrates different tasks such as image-to-video generation and video interpolation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Method Overview -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Method Overview</h2>
      <div class="publication-banner">
        <img src="static/images/flowception_schedule.jpg" alt="Flowception extended time scheduler illustration" loading="lazy"/>
      </div>
      <h2 class="subtitle has-text-centered" style="margin-top: 1.5rem;">
        Illustration of the extended time scheduler for Flowception training. In Flowception, each frame has its own denoising time which depends on its insertion time. The global extended time $\tau_g$ progresses from $0$ to $2$, where insertion of new frames only occur when $\tau_g < 1$. Starting frames (in blue) are instantiated at $\tau_g = 0$, other frames (in orange) are inserted later (when $τg > 0$) and thus have a delay. With a linear scheduler, the insertion delays follow a uniform distribution.
      </h2>
    </div>
  </div>
</section>
<!-- End Method Overview -->

<!-- schedule comparison -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Comparing methodologies</h2>

      <div class="columns is-vcentered is-variable is-6">
      <!-- Figure column -->
      <div class="column is-narrow">
        <div class="publication-banner">
          <figure class="image" style="max-width: 300px; margin: 0 auto;">
            <img src="static/animations/flowception_extended_and_visible.gif"
                alt="Flowception extended time scheduler illustration"
                loading="lazy">
          </figure>
        </div>
      </div>

      <!-- Text column -->
      <div class="column">
        <h2 class="subtitle" style="margin-top: 0;">
          Starting from a small set of frames, Flowception learns to flow existing frames while
          potentially inserting new frames anywhere in the sequence.<br>
          Since the latest insertions happens at \( \tau_g = 1 \), the maximum number of steps
          is capped to \( \frac{2}{h} \) where \( h \) is the sampling step size.<br>
          During training, frames are deleted with uniform probability in $[-1,0]$, and each existing frame predicts the missing number of frames in the gap with its sucessor.<br>
          
        </h2>
      </div>
    </div>



      <div class="columns is-vcentered is-centered">
        <div class="column is-one-third publication-banner">
          <img src="static/animations/full_sequence_flows.gif"
               alt="Flowception extended time scheduler illustration"
               loading="lazy"/>
        </div>

        <div class="column is-one-third publication-banner">
          <img src="static/animations/autoregressive_flows.gif"
               alt="Flowception extended time scheduler illustration"
               loading="lazy"/>
        </div>

        <div class="column is-one-third publication-banner">
          <img src="static/animations/flowception_visible_schedule.gif"
               alt="Flowception extended time scheduler illustration"
               loading="lazy"/>
        </div>
      </div>

    </div>
  </div>
</section>
<!-- End schedule comparison -->


<!-- capabilities -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Capabilities</h2>

      <div class="columns is-vcentered is-variable is-6">
      <!-- Figure column -->
      <div class="column is-narrow">
        <div class="publication-banner">
          <figure class="image" style="max-width: 400px; margin: 0 auto;">
            <img src="static/images/flowception_capabilities.png"
                alt="Flowception capabilities"
                loading="lazy">
          </figure>
        </div>
      </div>

      <!-- Text column -->
      <div class="column">
        <h2 class="subtitle" style="margin-top: 0;">
          Flowception seamlessly unifies multiple modalities by introducing context frames (i.e clean frames that are part of the visible sequence, which can potentially induce insertions).<br>
          By providing a set of context frames, the model is able to learn how many new frames to insert in order to generate a coherent video.
        </h2>
      </div>
    </div>
  </div>
</section>



<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Examples</h2>
      <div id="examples-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <img src="static/videos/kinetics_interp_0.gif" alt="Kinetics interpolation result 1" loading="lazy"/>
        </div>
        <div class="item item-video2">
          <img src="static/videos/kinetics_interp_1.gif" alt="Kinetics interpolation result 2" loading="lazy"/>
        </div>
        <div class="item item-video3">
          <img src="static/videos/kinetics_interp_2.gif" alt="Kinetics interpolation result 3" loading="lazy"/>
        </div>
        <div class="item item-video4">
          <img src="static/videos/kinetics_interp_3.gif" alt="Kinetics interpolation result 4" loading="lazy"/>
        </div>
        <div class="item item-video5">
          <img src="static/videos/kinetics_interp_4.gif" alt="Kinetics interpolation result 5" loading="lazy"/>
        </div>
        <div class="item item-video6">
          <img src="static/videos/re10k_interp_0.gif" alt="RE10K interpolation result 1" loading="lazy"/>
        </div>
        <div class="item item-video7">
          <img src="static/videos/re10k_interp_1.gif" alt="RE10K interpolation result 2" loading="lazy"/>
        </div>
        <div class="item item-video8">
          <img src="static/videos/re10k_interp_2.gif" alt="RE10K interpolation result 3" loading="lazy"/>
        </div>
        <div class="item item-video9">
          <img src="static/videos/re10k_interp_3.gif" alt="RE10K interpolation result 4" loading="lazy"/>
        </div>
        <div class="item item-video10">
          <img src="static/videos/re10k_interp_4.gif" alt="RE10K interpolation result 5" loading="lazy"/>
        </div>
        <div class="item item-video11">
          <img src="static/videos/taichi_i2v_0.gif" alt="Taichi image-to-video result 1" loading="lazy"/>
        </div>
        <div class="item item-video12">
          <img src="static/videos/taichi_i2v_1.gif" alt="Taichi image-to-video result 2" loading="lazy"/>
        </div>
        <div class="item item-video13">
          <img src="static/videos/taichi_i2v_2.gif" alt="Taichi image-to-video result 3" loading="lazy"/>
        </div>
        <div class="item item-video14">
          <img src="static/videos/taichi_i2v_3.gif" alt="Taichi image-to-video result 4" loading="lazy"/>
        </div>
        <div class="item item-video15">
          <img src="static/videos/taichi_i2v_4.gif" alt="Taichi image-to-video result 5" loading="lazy"/>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->









<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{BerradadIfriqi2025Flowception,
  title={Flowception: Temporally Expansive Flow Matching for Video Generation},
  author={Berrada Ifriqi, Tariq and Nguyen, John and Alahari, Karteek and Verbeek, Jakob and Chen, Ricky},
	  journal={arXiv preprint},
	  volume = {},
  year={2025},
  url={https://johnlnguyen.com/flowception/}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
